# vim: set ft=sh :
# Since I do not compile the package from source myself. 
# I woule backup previous PKGBUILD in case someone may need it.

# Contributor: Mantas Vidutis <mantas.a.vidutis-at-gmail.com>

pkgname=hadoop
pkgver=1.0.1
_devver=1.0.1-dev
pkgrel=1
pkgdesc="Hadoop - MapReduce implementation and distributed filesystem"
arch=('i686' 'x86_64')
url="http://hadoop.apache.org"
license=('APACHE')
depends=('java-runtime' 'zlib' 'gzip' 'lzo' 'bzip2')
makedepends=('java-environment' 'apache-ant')
optdepends=('kfs')
conflicts=('hadoop-svn')
install=hadoop.install
source=("http://mirror.csclub.uwaterloo.ca/apache/hadoop/common/hadoop-${pkgver}/hadoop-${pkgver}.tar.gz")
md5sums=('e627d9b688c4de03cba8313bd0bba148')

compile() {
  cd ${srcdir}/hadoop-${pkgver} || return 1

  msg "Cleaning..."
  ant clean || return 1

  msg "Patching..."
  sed -i "s/${_devver}/${pkgver}/" build.xml
  sed -i "s|<ivysettings>|<ivysettings>\n<caches defaultCacheDir=\"${srcdir}/ivy_cache\"/>|" ivy/ivysettings.xml

  msg "Building..."
  ant -Dcompile.native=true bin-package || return 1

  cd ${srcdir}/hadoop-${pkgver}/build || return 1

  msg "Installing..."
  mkdir -p ${pkgdir}/usr/share
  mkdir -p ${pkgdir}/usr/share/hadoop/etc/hadoop/

  mv hadoop-${pkgver} ${pkgdir}/usr/share/hadoop || return 1
  mv ${pkgdir}/usr/share/hadoop/conf ${pkgdir}/usr/share/hadoop/etc/hadoop/default || return 1
}

use_compiled() {
  msg "Installing..."

  mkdir -p ${pkgdir}/usr/share/hadoop
  mkdir -p ${pkgdir}/usr/share/hadoop/etc/hadoop/

  cd ${srcdir}/hadoop-${pkgver}

  mv bin lib webapps *.jar *.txt ${pkgdir}/usr/share/hadoop/ || return 1
  mv conf ${pkgdir}/usr/share/hadoop/etc/hadoop/default || return 1
}

build() {
  # compile
  use_compiled

  msg "Configuring..."

  cd ${pkgdir}/usr/share/hadoop/etc/hadoop/default || return 1

  # Set Java home:
  echo 'export JAVA_HOME=/opt/java/jre' >> hadoop-env.sh

  # Set directories:
  echo 'export HADOOP_LOG_DIR="/var/log/hadoop"' >> hadoop-env.sh
  echo 'export HADOOP_PID_DIR="/var/run"' >> hadoop-env.sh

  # Disable IPv6 (comment out for IPv6 support):
  sed -i 's|_OPTS="-D|_OPTS="-Djava.net.preferIPv4Stack=true -D|' hadoop-env.sh

  cd ${pkgdir}/usr/share/hadoop || return 1

  sed -i 's#^export HADOOP_HOME=`dirname "$this"`/..#export HADOOP_HOME="/usr/share/hadoop"\nexport HADOOP_CONF_DIR="/etc/hadoop"#' bin/hadoop-config.sh

  if [ "$CARCH" = "i686" ]; then
    rm -rf lib/native/Linux-amd64-64
    cd lib/native/Linux-i386-32
    sed -i "s|dependency_libs='|dependency_libs='-L/opt/java/jre/lib/i386/server |" libhadoop.la
  fi

  if [ "$CARCH" = "x86_64" ]; then
    rm -rf lib/native/Linux-i386-32
    cd lib/native/Linux-amd64-64
    sed -i "s|dependency_libs='|dependency_libs='-L/opt/java/jre/lib/amd64/server |" libhadoop.la
  fi

  # Create some links, so Hadoop's KFS jar could access KFS libraries properly
  # (it is still fine if KFS is not installed)

  msg "Creating KFS links..."

  for lib in libkfsClient libkfsCommon libkfsEmulator libkfsIO libkfsMeta; do
    for ext in a so; do
      ln -s /usr/lib/${lib}.${ext}
    done
  done

  ln -s /usr/lib/libkfs_access.so
}

# put follow in hadoop.install

post_install() {
        for src in /usr/share/hadoop/etc/hadoop/default/*; do
                dest=$( echo $src | sed 's|^/usr/share/hadoop/etc/hadoop/default/|/usr/share/hadoop/etc/hadoop/|' )
                if [ -f $dest ]; then
                        diff $src $dest > /dev/null 2>/dev/null
                        ret=$?
       		
                        if [ $ret -ne 0 ]; then
                                echo ">>> Not updating $dest - it exists and is different than $src. Please check if it needs to be modified."
                        fi
                else
                        echo ">>> Copying $src to $dest"
                        cp $src $dest
                fi
         done
}

post_upgrade() {
        post_install
}

